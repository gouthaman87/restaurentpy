{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from restaurentpy.data import ReviewData\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ReviewData(path='/Volumes/Macintosh HD/AI World/Review Data/BigPlate/', pat='xlsx').etl_review()\n",
    "df['translate_review'] = df['review_text'].apply(lambda x: clean(x, no_emoji=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bertopic ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "topic_model = BERTopic(representation_model = representation_model)\n",
    "\n",
    "print('Training topic model for reviews...')\n",
    "topics, ini_probs = topic_model.fit_transform(list(df.translate_review.values))\n",
    "\n",
    "df['topic'] = topics\n",
    "df['topic_prob'] = ini_probs\n",
    "\n",
    "topics_info = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_number = 3\n",
    "\n",
    "print( 'Reviews: \\n' ,'\\n'.join([str(elem) for elem in \\\n",
    "                                df[df['topic']==topic_number]\\\n",
    "                                    .sort_values('topic_prob', ascending=False)\\\n",
    "                                    .drop_duplicates(subset=['review_text'])['review_text']\\\n",
    "                                        .head(4).values])\n",
    ")\n",
    "\n",
    "print( '\\nKey words: ' ,', '.join([str(elem) for elem in \\\n",
    "    topics_info.loc[topics_info['Topic']==topic_number, 'Representation'].values[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant for labeling topics.\n",
    "<</SYS>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt \n",
    "example_prompt = \"\"\"\n",
    "I have a topic that contains the following documents (from customers reviews):\n",
    "- Not good. Fries were stale.\n",
    "- There burgers has gotten worse than ever but their fries are still good.\n",
    "- Fries were too salty.\n",
    "\n",
    "The topic is described by the following keywords: 'fries, fry, burger, burgers, fried, cold, frozen, cooked, greasy, warm'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "\n",
    "[/INST] bad food\n",
    "\"\"\"\n",
    "\n",
    "base_prompt = system_prompt + example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# Quantity of reviews\n",
    "qty_comments_prompt = 10\n",
    "\n",
    "def get_short_labels(df, topics_info, qty_comments_prompt, base_prompt):\n",
    "    for topic in topics_info.loc[topics_info['Topic'] > -1, 'Topic']:\n",
    "        print(topic)\n",
    "        # X reviews with the higher probability. It doesn't consider the duplicated values\n",
    "        comments_list = '\\n- '.join([str(elem) for elem in \\\n",
    "                                df[df['topic']==topic].sort_values('topic_prob', ascending=False)\\\n",
    "                                    .drop_duplicates(subset=['translate_review'])['translate_review']\\\n",
    "                                        .head(qty_comments_prompt).values])\n",
    "        \n",
    "        # Key words list from topic        \n",
    "        key_list = ', '.join([str(elem) for elem in topics_info.loc[topics_info['Topic']==topic, 'Representation'].values[0]])\n",
    "\n",
    "        # The main prompt with the list of reviews and list of topic key words\n",
    "        main_prompt = f\"\"\"\n",
    "[INST]\n",
    "I have a topic that contains the following documents (from customers reviews):\n",
    "{comments_list}\n",
    "\n",
    "The topic is described by the following keywords: '{key_list}'.\n",
    "\n",
    "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
    "[/INST]\n",
    "        \"\"\"\n",
    "        # Build input prompt\n",
    "        prompt = base_prompt + main_prompt\n",
    "       \n",
    "        output = ollama.generate(model='llama3', prompt=prompt)\n",
    "        topics_info.loc[topics_info['Topic']==topic, 'short_label'] = output['response']\n",
    "\n",
    "        print('Output: ', output['response'])\n",
    "    return topics_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training topic model with Negative customer reviews\n",
    "topics_info_output = get_short_labels(df, topics_info, qty_comments_prompt, base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_info_output.short_label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "restaurentpy-gkgQl5iP-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
